# -*- coding: utf-8 -*-
import urllib.request
import json
import re
from html import  unescape
"""
微博爬取功能的实现
"""

#设置代理IP
proxy_addr="122.241.72.191:808"

#定义页面打开函数
def use_proxy(url,proxy_addr="122.241.72.191:808"):
    req=urllib.request.Request(url)
    req.add_header("User-Agent","Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.221 Safari/537.36 SE 2.X MetaSr 1.0")
    proxy=urllib.request.ProxyHandler({'http':proxy_addr})
    opener=urllib.request.build_opener(proxy,urllib.request.HTTPHandler)
    urllib.request.install_opener(opener)
    data=urllib.request.urlopen(req).read().decode('utf-8','ignore')
    return data

#获取微博主页的containerid，爬取微博内容时需要此id
def get_containerid(url):
    data=use_proxy(url,proxy_addr)
    content=json.loads(data).get('data')
    for data in content.get('tabsInfo').get('tabs'):
        if(data.get('tab_type')=='weibo'):
            containerid=data.get('containerid')
    return containerid

#获取微博大V账号的用户基本信息，如：微博昵称、微博地址、微博头像、关注人数、粉丝数、性别、等级等
def get_userInfo(id):
    url='https://m.weibo.cn/api/container/getIndex?type=uid&value='+id
    data=use_proxy(url,proxy_addr)
    content=json.loads(data).get('data')
    profile_image_url=content.get('userInfo').get('profile_image_url')
    description=content.get('userInfo').get('description')
    profile_url=content.get('userInfo').get('profile_url')
    verified=content.get('userInfo').get('verified')
    guanzhu=content.get('userInfo').get('follow_count')
    name=content.get('userInfo').get('screen_name')
    fensi=content.get('userInfo').get('followers_count')
    gender=content.get('userInfo').get('gender')
    urank=content.get('userInfo').get('urank')
    #print("微博昵称："+name+"\n"+"微博主页地址："+profile_url+"\n"+"微博头像地址："+profile_image_url+"\n"+"是否认证："+str(verified)+"\n"+"微博说明："+description+"\n"+"关注人数："+str(guanzhu)+"\n"+"粉丝数："+str(fensi)+"\n"+"性别："+gender+"\n"+"微博等级："+str(urank)+"\n")

#提取html标签中的内容
def get_text(html):
    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)
    text = re.sub('<a\s.*?>', '', text, flags=re.M | re.S | re.I)
    text = re.sub('<.*?>', '', text, flags=re.M | re.S)
    text = re.sub(r'(\s*\n)+', '\n', text, flags=re.M | re.S)
    print(text)
    return unescape(text)

#获取微博内容信息,并保存到文本中，内容包括：每条微博的内容、微博详情页面地址、点赞数、评论数、转发数等
def get_weibo(id):
    url='https://m.weibo.cn/api/container/getIndex?type=uid&value='+id
    weibo_url='https://m.weibo.cn/api/container/getIndex?type=uid&value='+id+'&containerid='+get_containerid(url)+'&page='+str(1)
    try:
        data=use_proxy(weibo_url,proxy_addr)
        content=json.loads(data).get('data')
        cards=content.get('cards')
        if(len(cards)>0):
            for j in range(len(cards)):
                card_type=cards[j].get('card_type')
                if(card_type==9):
                    mblog=cards[j].get('mblog')
                    if mblog.get('title'):
                        flag = mblog.get('title')['text']
                    else:
                        flag = ''
                    if str(flag) != '置顶':
                        attitudes_count = mblog.get('attitudes_count')
                        comments_count = mblog.get('comments_count')
                        created_at = mblog.get('created_at')
                        reposts_count = mblog.get('reposts_count')
                        scheme = cards[j].get('scheme')
                        text = mblog.get('text')
                        text = get_text(text) # html格式提取text
                        #text = text.replace('HYPERLINK','')
                        #print(text)
                        res = {"scheme":scheme,"created_at":created_at,"text":text}
                        print("微博地址："+str(scheme)+"\n"+"发布时间："+str(created_at)+"\n"+"微博内容："+text+"\n"+"点赞数："+str(attitudes_count)+"\n"+"评论数："+str(comments_count)+"\n"+"转发数："+str(reposts_count)+"\n")
                        return res
                    else:
                        pass
        else:
            pass
    except Exception as e:
        print(e)
        pass
# 这是执行的主函数
def weibo_content(content):
    id_dict = {'张宇':'2058586920','汤家凤':'2644595644',
                 '肖秀荣':'1227078145','李永乐':'2440693053',
                 '李林':'6444289173','唐迟':'1491569192',
                 '谭剑波':'2056180751','朱伟':'1190953227',
                 '商志':'1114286271','陆寓丰':'1925027893'}
    if content in id_dict:
        data = get_weibo(id_dict[content])
        res = "[QQ:face=175]" + content+"在" + str(data['created_at']) + "更新了微博" + str(data['scheme'])+"\n主要内容:\n"+str(data['text'])
        return res
    else:
        return None
# 测试
# weibo_content('张宇')